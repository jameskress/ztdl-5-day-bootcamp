{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification\n",
    "\n",
    "- Pandas Documentation: http://pandas.pydata.org/\n",
    "- Scikit Learn Documentation: http://scikit-learn.org/stable/documentation.html\n",
    "- Seaborn Documentation: http://seaborn.pydata.org/\n",
    "- Keras Documentation: https://keras.io\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text classification\n",
    "\n",
    "Our goal is to perform a binary classification on text data. We will perform both a Spam detection example and a Sentiment analysis example. We will attempt 3 strategies:\n",
    "\n",
    "1) build naive features based on our ideas\n",
    "\n",
    "2) use well tested feature extraction technique\n",
    "\n",
    "3) use deep learning and recurrent models on text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Spam detection on SMS messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>msg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                                msg\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/sms.tsv', sep='\\t')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     0.865937\n",
       "spam    0.134063\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts() / len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise1: Encode Labels to 0 and 1\n",
    "\n",
    "Create a variable called y that contains 0 for HAM messages and 1 for SPAM messages. There are several ways to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "tags": [
     "solution",
     "empty"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "y = le.fit_transform(df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "tags": [
     "solution"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ham', 'spam'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "tags": [
     "solution"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Build naive features based on keywords\n",
    "\n",
    "- turn all your sms messages to lowercase\n",
    "- define a function to count occurrences of a single keyword with the following signature:\n",
    "\n",
    "        def count_word(word, sentence):\n",
    "            ....\n",
    "            return count_word_in_sentence\n",
    "            \n",
    "            \n",
    "- to test your function, try it on these examples and check that the results match:\n",
    "   \n",
    "        count_word(\"the\", \"quick brown fox\") # -> 0\n",
    "        count_word(\"fox\", \"quick brown fox\") # -> 1\n",
    "        count_word(\"a\", \"a b a abab\") # -> 2\n",
    "     \n",
    "\n",
    "- using the function `count_word` you just wrote, create a feature matrix `X` using counts of some keywords of your choice. (this will a bag-of-words representation.)\n",
    "- create other similar features. You could use:\n",
    "    - the length of the message\n",
    "    - the presence of numbers\n",
    "    - the presence of special characters\n",
    "    - ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "tags": [
     "solution",
     "empty"
    ]
   },
   "outputs": [],
   "source": [
    "docs = df['msg'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "docs_lower = [d.lower() for d in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "def count_word(word, sentence):\n",
    "    tokens = sentence.split()\n",
    "    return len([w for w in tokens if w == word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "X = pd.DataFrame([count_word('free', d) for d in docs_lower], columns=['free'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "for keyword in ['win', 'discount', 'call']:\n",
    "    X[keyword] = [count_word(keyword, d) for d in docs_lower]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "def count_numbers(sentence):\n",
    "    return len(re.findall('[0-9]', sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "X['num_char'] = [count_numbers(d) for d in docs_lower]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "tags": [
     "solution"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>free</th>\n",
       "      <th>win</th>\n",
       "      <th>discount</th>\n",
       "      <th>call</th>\n",
       "      <th>num_char</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   free  win  discount  call  num_char\n",
       "0     0    0         0     0         0\n",
       "1     0    0         0     0         0\n",
       "2     1    1         0     0        25\n",
       "3     0    0         0     0         0\n",
       "4     0    0         0     0         0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Train first model and evaluate performance\n",
    "\n",
    "- split data in to train and test sets with `test_size=0.3, random_state=0`. you can use the `train_test_split` function from sklearn, which we have used in previous labs\n",
    "- train model of your choice on these features\n",
    "- evaluate performance on training and test set\n",
    "- discuss with classmate:\n",
    "    - how did you evaluate performance?\n",
    "    - is model overfitting?\n",
    "    - is model better than benchmark?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "tags": [
     "solution",
     "empty"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X.values, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "tags": [
     "solution"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=100, n_jobs=-1)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "tags": [
     "solution"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9766666666666667"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "tags": [
     "solution"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9742822966507177"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "tags": [
     "solution"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.867823\n",
       "1    0.132177\n",
       "dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_test).value_counts() / len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4: Cross Validation\n",
    "\n",
    "- perform a 5-Fold cross validation on your model. you can refer back to lab 8 to refresh your memory on how to do this.\n",
    "- print the confusion matrix and the classification report on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "tags": [
     "solution",
     "empty"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "tags": [
     "solution"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9793722 , 0.97668161, 0.96947935, 0.96858169, 0.97666068])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(model, X, y, cv = 5, n_jobs=-1)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "tags": [
     "solution"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average score: 0.974 +/- 0.00431\n"
     ]
    }
   ],
   "source": [
    "print(\"Average score: {:0.3} +/- {:0.3}\".format(scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "tags": [
     "solution"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.99      0.99      1451\n",
      "          1       0.93      0.87      0.90       221\n",
      "\n",
      "avg / total       0.97      0.97      0.97      1672\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "tags": [
     "solution"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_ham</th>\n",
       "      <th>pred_spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ham</th>\n",
       "      <td>1436</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>28</td>\n",
       "      <td>193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      pred_ham  pred_spam\n",
       "ham       1436         15\n",
       "spam        28        193"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "pd.DataFrame(cm,\n",
    "             index=['ham', 'spam'],\n",
    "             columns=['pred_ham', 'pred_spam'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5: Count Features\n",
    "\n",
    "- use features based on word counts using the `CountVectorizer` class from Scikit Learn\n",
    "- use the following function to simplify your code (it encapsulates model training and evaluation):\n",
    "\n",
    "\n",
    "    def split_fit_eval(X, y, model=None, epochs=10, random_state=0):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=random_state)\n",
    "\n",
    "        if not model:\n",
    "            model = Sequential()\n",
    "            model.add(Dense(1, input_dim=X.shape[1], activation='sigmoid'))\n",
    "\n",
    "            model.compile(loss='binary_crossentropy',\n",
    "                          optimizer='adam',\n",
    "                          metrics=['accuracy'])\n",
    "\n",
    "        h = model.fit(X_train, y_train, epochs=epochs, verbose=1)\n",
    "\n",
    "        train_loss, train_acc = model.evaluate(X_train, y_train)\n",
    "        test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "\n",
    "        return train_loss, train_acc, test_loss, test_acc, model, h\n",
    "\n",
    "\n",
    "- did you improve the performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "tags": [
     "solution",
     "empty"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "vocab_size = 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "vect = CountVectorizer(decode_error='ignore',\n",
    "                       stop_words='english',\n",
    "                       lowercase=True,\n",
    "                       max_features=vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true,
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "X = vect.fit_transform(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "Xd = X.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true,
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "vocab = vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true,
    "tags": [
     "solution"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00',\n",
       " '000',\n",
       " '02',\n",
       " '0207',\n",
       " '02073162414',\n",
       " '03',\n",
       " '04',\n",
       " '05',\n",
       " '06',\n",
       " '07123456789']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true,
    "tags": [
     "solution"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['yogasana', 'yor', 'yr', 'yrs', 'yummy', 'yun', 'yunny', 'yuo', 'yup', 'zed']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true,
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true,
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "def split_fit_eval(X, y, model=None, epochs=10, random_state=0):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=random_state)\n",
    "    \n",
    "    if not model:\n",
    "        model = Sequential()\n",
    "        model.add(Dense(1, input_dim=X.shape[1], activation='sigmoid'))\n",
    "\n",
    "        model.compile(loss='binary_crossentropy',\n",
    "                      optimizer='adam',\n",
    "                      metrics=['accuracy'])\n",
    "    \n",
    "    h = model.fit(X_train, y_train, epochs=epochs, verbose=1)\n",
    "    \n",
    "    train_loss, train_acc = model.evaluate(X_train, y_train)\n",
    "    test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "    \n",
    "    return train_loss, train_acc, test_loss, test_acc, model, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true,
    "tags": [
     "solution"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4179/4179 [==============================] - 2s 541us/step - loss: 0.6114 - acc: 0.8909\n",
      "Epoch 2/10\n",
      "4179/4179 [==============================] - 1s 236us/step - loss: 0.4850 - acc: 0.9636\n",
      "Epoch 3/10\n",
      "4179/4179 [==============================] - 1s 248us/step - loss: 0.3988 - acc: 0.9682\n",
      "Epoch 4/10\n",
      "4179/4179 [==============================] - 1s 255us/step - loss: 0.3370 - acc: 0.9720\n",
      "Epoch 5/10\n",
      "4179/4179 [==============================] - 1s 261us/step - loss: 0.2910 - acc: 0.9730\n",
      "Epoch 6/10\n",
      "4179/4179 [==============================] - 1s 246us/step - loss: 0.2554 - acc: 0.9761\n",
      "Epoch 7/10\n",
      "4179/4179 [==============================] - 1s 236us/step - loss: 0.2272 - acc: 0.9782\n",
      "Epoch 8/10\n",
      "4179/4179 [==============================] - 1s 241us/step - loss: 0.2042 - acc: 0.9794\n",
      "Epoch 9/10\n",
      "4179/4179 [==============================] - 1s 258us/step - loss: 0.1852 - acc: 0.9806\n",
      "Epoch 10/10\n",
      "4179/4179 [==============================] - 1s 259us/step - loss: 0.1692 - acc: 0.9809\n",
      "4179/4179 [==============================] - 1s 125us/step\n",
      "1393/1393 [==============================] - 0s 126us/step\n"
     ]
    }
   ],
   "source": [
    "res = split_fit_eval(Xd, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true,
    "tags": [
     "solution"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9815745394633244"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true,
    "tags": [
     "solution"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9777458722610227"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis\n",
    "\n",
    "The previous dataset was easy. Let's switch to a harder one and do sentiment analysis on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>critic</th>\n",
       "      <th>fresh</th>\n",
       "      <th>imdb</th>\n",
       "      <th>publication</th>\n",
       "      <th>quote</th>\n",
       "      <th>review_date</th>\n",
       "      <th>rtid</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Derek Adams</td>\n",
       "      <td>fresh</td>\n",
       "      <td>114709.0</td>\n",
       "      <td>Time Out</td>\n",
       "      <td>So ingenious in concept, design and execution ...</td>\n",
       "      <td>2009-10-04</td>\n",
       "      <td>9559.0</td>\n",
       "      <td>Toy story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Richard Corliss</td>\n",
       "      <td>fresh</td>\n",
       "      <td>114709.0</td>\n",
       "      <td>TIME Magazine</td>\n",
       "      <td>The year's most inventive comedy.</td>\n",
       "      <td>2008-08-31</td>\n",
       "      <td>9559.0</td>\n",
       "      <td>Toy story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>David Ansen</td>\n",
       "      <td>fresh</td>\n",
       "      <td>114709.0</td>\n",
       "      <td>Newsweek</td>\n",
       "      <td>A winning animated feature that has something ...</td>\n",
       "      <td>2008-08-18</td>\n",
       "      <td>9559.0</td>\n",
       "      <td>Toy story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Leonard Klady</td>\n",
       "      <td>fresh</td>\n",
       "      <td>114709.0</td>\n",
       "      <td>Variety</td>\n",
       "      <td>The film sports a provocative and appealing st...</td>\n",
       "      <td>2008-06-09</td>\n",
       "      <td>9559.0</td>\n",
       "      <td>Toy story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jonathan Rosenbaum</td>\n",
       "      <td>fresh</td>\n",
       "      <td>114709.0</td>\n",
       "      <td>Chicago Reader</td>\n",
       "      <td>An entertaining computer-generated, hyperreali...</td>\n",
       "      <td>2008-03-10</td>\n",
       "      <td>9559.0</td>\n",
       "      <td>Toy story</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               critic  fresh      imdb     publication  \\\n",
       "0         Derek Adams  fresh  114709.0        Time Out   \n",
       "1     Richard Corliss  fresh  114709.0   TIME Magazine   \n",
       "2         David Ansen  fresh  114709.0        Newsweek   \n",
       "3       Leonard Klady  fresh  114709.0         Variety   \n",
       "4  Jonathan Rosenbaum  fresh  114709.0  Chicago Reader   \n",
       "\n",
       "                                               quote review_date    rtid  \\\n",
       "0  So ingenious in concept, design and execution ...  2009-10-04  9559.0   \n",
       "1                  The year's most inventive comedy.  2008-08-31  9559.0   \n",
       "2  A winning animated feature that has something ...  2008-08-18  9559.0   \n",
       "3  The film sports a provocative and appealing st...  2008-06-09  9559.0   \n",
       "4  An entertaining computer-generated, hyperreali...  2008-03-10  9559.0   \n",
       "\n",
       "       title  \n",
       "0  Toy story  \n",
       "1  Toy story  \n",
       "2  Toy story  \n",
       "3  Toy story  \n",
       "4  Toy story  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/rt_critics.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14072 entries, 0 to 14071\n",
      "Data columns (total 8 columns):\n",
      "critic         13382 non-null object\n",
      "fresh          14072 non-null object\n",
      "imdb           14072 non-null float64\n",
      "publication    14072 non-null object\n",
      "quote          14072 non-null object\n",
      "review_date    14072 non-null object\n",
      "rtid           14072 non-null float64\n",
      "title          14072 non-null object\n",
      "dtypes: float64(2), object(6)\n",
      "memory usage: 879.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fresh     0.612067\n",
       "rotten    0.386299\n",
       "none      0.001634\n",
       "Name: fresh, dtype: float64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['fresh'].value_counts() / len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fresh     0.613069\n",
       "rotten    0.386931\n",
       "Name: fresh, dtype: float64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df.fresh != 'none'].copy()\n",
    "df['fresh'].value_counts() / len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = le.fit_transform(df['fresh'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6: TFIDF\n",
    "\n",
    "- Build features with word frequencies (Tfidf). (sklearn has a preprocessor for this.)\n",
    "- do train/test split\n",
    "- train and evaluate a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true,
    "tags": [
     "solution",
     "empty"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true,
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer(decode_error='ignore',\n",
    "                       stop_words='english',\n",
    "                       max_features=20000)\n",
    "\n",
    "X = vect.fit_transform(df['quote'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true,
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true,
    "tags": [
     "solution"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=100, n_jobs=-1)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true,
    "tags": [
     "solution"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9997966239576977"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true,
    "tags": [
     "solution"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7034400948991696"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 7: NLP with deep learning\n",
    "\n",
    "- Use the Tokenizer from Keras to:\n",
    "    - Create a vocabulary\n",
    "    - Convert sentences to sequences of integers\n",
    "- pad the sequences so that they look like a tensor using the pad_sequences function from Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "solution",
     "empty"
    ]
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=20000)\n",
    "\n",
    "docs = df['quote']\n",
    "tokenizer.fit_on_texts(docs)\n",
    "sequences = tokenizer.texts_to_sequences(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "source": [
    "- check max word index\n",
    "- check max sequence length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "max_features = max([max(seq) for seq in sequences if len(seq) > 0]) + 1\n",
    "max_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "maxlen = max([len(seq) for seq in sequences])\n",
    "maxlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "X = pad_sequences(sequences, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train / Test split on sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 8: Build recurrent neural network model\n",
    "- use what you have learned to build a recurrent model that classifies the sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "empty",
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Embedding\n",
    "from keras.layers import LSTM, GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=max_features,\n",
    "                    output_dim=32,\n",
    "                    input_length=maxlen))\n",
    "model.add(LSTM(32))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "h = model.fit(X_train, y_train, batch_size=64, epochs=4, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "model.evaluate(X_train, y_train, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "loss, acc = model.evaluate(X_test, y_test, batch_size=32)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(h.history).plot(ylim=(-0.05, 1.05))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 9\n",
    "\n",
    "- Try changing the network architecture and re-train the model at each change. Can you avoid overfitting?\n",
    "    - change the number of nodes in the LSTM layer\n",
    "    - change the output dimension of the Embedding layer\n",
    "    - add dropout and recurrent dropout to the LSTM\n",
    "    - add a second LSTM layer\n",
    "    - add kernel regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
